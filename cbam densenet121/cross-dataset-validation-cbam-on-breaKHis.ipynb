{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":999617,"sourceType":"datasetVersion","datasetId":209316},{"sourceId":535254,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":416364,"modelId":434096}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom sklearn.metrics import (\n    roc_auc_score, average_precision_score, accuracy_score, \n    f1_score, classification_report, confusion_matrix, precision_recall_curve, roc_curve\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom collections import defaultdict\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -----------------------------\n# Define CBAM Module\n# -----------------------------\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\nclass CBAM(nn.Module):\n    def __init__(self, in_planes, ratio=16, kernel_size=7):\n        super(CBAM, self).__init__()\n        self.ca = ChannelAttention(in_planes, ratio)\n        self.sa = SpatialAttention(kernel_size)\n\n    def forward(self, x):\n        x = x * self.ca(x)\n        x = x * self.sa(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Load PCam-trained DenseNet121-CBAM Model\n# -----------------------------\ndef load_pcam_model(model_path, device):\n    \"\"\"Load DenseNet121 with CBAM attention modules\"\"\"\n    # Load base DenseNet121\n    model = models.densenet121(weights=None)\n    \n    # Get the number of output channels for each dense block\n    # DenseNet121 feature channels: 64 -> 128 -> 256 -> 512 -> 1024\n    cbam_positions = {\n        'denseblock1': 256,   # After first dense block\n        'denseblock2': 512,   # After second dense block  \n        'denseblock3': 1024,  # After third dense block\n        'denseblock4': 1024   # After fourth dense block\n    }\n    \n    # Add CBAM modules after each dense block\n    for name, channels in cbam_positions.items():\n        cbam_module = CBAM(channels)\n        setattr(model.features, f'{name}_cbam', cbam_module)\n    \n    # Modify the forward pass to include CBAM\n    original_forward = model.features.forward\n    \n    def new_forward(x):\n        features = model.features\n        x = features.conv0(x)\n        x = features.norm0(x)\n        x = features.relu0(x)\n        x = features.pool0(x)\n        \n        # Process through dense blocks with CBAM\n        x = features.denseblock1(x)\n        x = features.denseblock1_cbam(x) if hasattr(features, 'denseblock1_cbam') else x\n        x = features.transition1(x)\n        \n        x = features.denseblock2(x)\n        x = features.denseblock2_cbam(x) if hasattr(features, 'denseblock2_cbam') else x\n        x = features.transition2(x)\n        \n        x = features.denseblock3(x)\n        x = features.denseblock3_cbam(x) if hasattr(features, 'denseblock3_cbam') else x\n        x = features.transition3(x)\n        \n        x = features.denseblock4(x)\n        x = features.denseblock4_cbam(x) if hasattr(features, 'denseblock4_cbam') else x\n        \n        x = features.norm5(x)\n        return x\n    \n    model.features.forward = new_forward\n    \n    # Modify classifier for binary classification\n    num_ftrs = model.classifier.in_features\n    model.classifier = nn.Linear(num_ftrs, 1)\n    \n    # Load weights with flexible matching\n    try:\n        checkpoint = torch.load(model_path, map_location=device)\n        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n            state_dict = checkpoint['state_dict']\n        else:\n            state_dict = checkpoint\n        \n        # Clean state dict keys\n        new_state_dict = {}\n        for k, v in state_dict.items():\n            # Remove 'module.' prefix if present\n            key = k[7:] if k.startswith('module.') else k\n            new_state_dict[key] = v\n        \n        # Load state dict with strict=False to handle architectural differences\n        model.load_state_dict(new_state_dict, strict=False)\n        print(\"‚úÖ Model loaded successfully with CBAM integration\")\n        \n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        raise\n    \n    model = model.to(device)\n    model.eval()\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Enhanced BreakHis Dataset Class\n# -----------------------------\nclass BreakHisDataset(Dataset):\n    def __init__(self, root_dir, transform=None, magnification=None):\n        self.samples = []\n        self.metadata = []\n        self.transform = transform\n        self.class_to_idx = {'benign': 0, 'malignant': 1}\n        self.magnifications = set()\n        self.tumor_types = defaultdict(int)\n        \n        print(f\"Scanning dataset directory: {root_dir}\")\n        \n        for class_name in ['benign', 'malignant']:\n            class_dir = os.path.join(root_dir, class_name)\n            \n            if not os.path.exists(class_dir):\n                print(f\"  ‚ö†Ô∏è  Class directory not found: {class_dir}\")\n                continue\n                \n            print(f\"  ‚úÖ Found {class_name} directory\")\n            \n            # Check if SOB subdirectory exists\n            sob_dir = os.path.join(class_dir, \"SOB\")\n            if os.path.exists(sob_dir):\n                tumor_base_dir = sob_dir\n            else:\n                tumor_base_dir = class_dir\n                \n            for tumor_type_dir in os.listdir(tumor_base_dir):\n                tumor_type_path = os.path.join(tumor_base_dir, tumor_type_dir)\n                if not os.path.isdir(tumor_type_path):\n                    continue\n                    \n                for patient_dir in os.listdir(tumor_type_path):\n                    patient_path = os.path.join(tumor_type_path, patient_dir)\n                    if not os.path.isdir(patient_path):\n                        continue\n                        \n                    for mag in os.listdir(patient_path):\n                        if magnification and mag != magnification:\n                            continue\n                            \n                        mag_dir = os.path.join(patient_path, mag)\n                        if not os.path.isdir(mag_dir):\n                            continue\n                        \n                        self.magnifications.add(mag)\n                        \n                        for fname in os.listdir(mag_dir):\n                            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n                                img_path = os.path.join(mag_dir, fname)\n                                self.samples.append((img_path, self.class_to_idx[class_name]))\n                                self.metadata.append({\n                                    'path': img_path,\n                                    'class': class_name,\n                                    'tumor_type': tumor_type_dir,\n                                    'patient': patient_dir,\n                                    'magnification': mag,\n                                    'filename': fname\n                                })\n                                self.tumor_types[f\"{class_name}_{tumor_type_dir}\"] += 1\n        \n        print(f\"\\nüìä Dataset Statistics:\")\n        print(f\"   Total images: {len(self.samples)}\")\n        if len(self.samples) > 0:\n            print(f\"   Magnifications: {sorted(self.magnifications)}\")\n            print(f\"   Tumor type distribution:\")\n            for tumor_type, count in sorted(self.tumor_types.items()):\n                print(f\"     {tumor_type}: {count}\")\n        else:\n            print(\"   ‚ùå No images found!\")\n        \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        try:\n            image = Image.open(img_path).convert('RGB')\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            return image, label, idx\n        except Exception as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            # Return a dummy image in case of error\n            dummy_image = torch.zeros(3, 128, 128) if self.transform else Image.new('RGB', (128, 128))\n            return dummy_image, label, idx\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Evaluation Functions\n# -----------------------------\ndef evaluate_by_magnification(model, dataset, device, batch_size=32):\n    \"\"\"Evaluate model performance by magnification level\"\"\"\n    results_by_mag = {}\n    \n    for mag in sorted(dataset.magnifications):\n        print(f\"\\nEvaluating magnification {mag}...\")\n        \n        # Create subset for this magnification\n        mag_indices = [i for i, meta in enumerate(dataset.metadata) \n                      if meta['magnification'] == mag]\n        \n        if len(mag_indices) == 0:\n            continue\n            \n        mag_dataset = torch.utils.data.Subset(dataset, mag_indices)\n        mag_loader = DataLoader(mag_dataset, batch_size=batch_size, \n                               shuffle=False, num_workers=2, pin_memory=True)\n        \n        all_preds = []\n        all_labels = []\n        all_probs = []\n        \n        with torch.no_grad():\n            for images, labels, _ in mag_loader:\n                images = images.to(device, non_blocking=True)\n                labels = labels.float().to(device, non_blocking=True)\n                \n                outputs = model(images)\n                probabilities = torch.sigmoid(outputs).cpu().numpy().flatten()\n                predictions = (probabilities > 0.5).astype(int)\n                \n                all_probs.extend(probabilities)\n                all_preds.extend(predictions)\n                all_labels.extend(labels.cpu().numpy())\n        \n        all_probs = np.array(all_probs)\n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        \n        if len(all_labels) > 0:\n            results_by_mag[mag] = {\n                'roc_auc': roc_auc_score(all_labels, all_probs),\n                'pr_auc': average_precision_score(all_labels, all_probs),\n                'accuracy': accuracy_score(all_labels, all_preds),\n                'f1_score': f1_score(all_labels, all_preds),\n                'sample_count': len(all_labels),\n                'predictions': all_preds,\n                'labels': all_labels,\n                'probabilities': all_probs\n            }\n            \n            print(f\"  Accuracy: {results_by_mag[mag]['accuracy']:.4f}\")\n            print(f\"  ROC-AUC: {results_by_mag[mag]['roc_auc']:.4f}\")\n            print(f\"  Samples: {results_by_mag[mag]['sample_count']}\")\n        else:\n            print(f\"  No samples found for magnification {mag}\")\n    \n    return results_by_mag","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Main Evaluation Script\n# -----------------------------\ndef main():\n    # Data preprocessing\n    transform = transforms.Compose([\n        transforms.Resize((128, 128)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load model\n    model_path = \"/kaggle/input/densenet121-cbam/pytorch/default/1/densenet121_chunked.pth\"\n    print(\"Loading PCam-trained DenseNet121-CBAM model...\")\n    \n    try:\n        model = load_pcam_model(model_path, device)\n    except Exception as e:\n        print(f\"‚ùå Failed to load model: {e}\")\n        return\n    \n    # Load BreakHis dataset\n    breakhis_root = \"/kaggle/input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast\"\n    print(f\"\\nLoading BreakHis dataset from: {breakhis_root}\")\n    \n    if not os.path.exists(breakhis_root):\n        print(f\"‚ùå Error: Dataset path does not exist: {breakhis_root}\")\n        return\n    \n    breakhis_dataset = BreakHisDataset(\n        root_dir=breakhis_root,\n        transform=transform,\n        magnification=None  # Use all magnifications\n    )\n    \n    if len(breakhis_dataset) == 0:\n        print(\"‚ùå Error: No samples found in dataset!\")\n        return\n    \n    # Overall evaluation\n    print(f\"\\n{'='*60}\")\n    print(\"CROSS-DATASET VALIDATION: PCam ‚Üí BreakHis\")\n    print(f\"{'='*60}\")\n    \n    breakhis_loader = DataLoader(\n        breakhis_dataset,\n        batch_size=32,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # Overall evaluation\n    start_time = time.time()\n    all_preds = []\n    all_labels = []\n    all_probabilities = []\n    \n    print(\"Starting model evaluation...\")\n    \n    try:\n        with torch.no_grad():\n            for batch_idx, (images, labels, _) in enumerate(breakhis_loader):\n                images = images.to(device, non_blocking=True)\n                labels = labels.float().to(device, non_blocking=True)\n                \n                outputs = model(images)\n                probabilities = torch.sigmoid(outputs).cpu().numpy().flatten()\n                predictions = (probabilities > 0.5).astype(int)\n                \n                all_probabilities.extend(probabilities)\n                all_preds.extend(predictions)\n                all_labels.extend(labels.cpu().numpy())\n                \n                if batch_idx % 50 == 0:\n                    print(f\"Processed batch {batch_idx}/{len(breakhis_loader)} \"\n                          f\"({len(all_labels)} samples so far)\")\n                    \n    except Exception as e:\n        print(f\"‚ùå Error during evaluation: {e}\")\n        return\n    \n    evaluation_time = time.time() - start_time\n    all_probabilities = np.array(all_probabilities)\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    if len(all_labels) == 0:\n        print(\"‚ùå Error: No samples were processed!\")\n        return\n    \n    print(f\"‚úÖ Processed {len(all_labels)} samples successfully\")\n    \n    # Calculate overall metrics\n    roc_auc = roc_auc_score(all_labels, all_probabilities)\n    pr_auc = average_precision_score(all_labels, all_probabilities)\n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    print(f\"\\n{'='*40}\")\n    print(\"OVERALL RESULTS\")\n    print(f\"{'='*40}\")\n    print(f\"Evaluation time    : {evaluation_time:.1f} seconds\")\n    print(f\"Total samples      : {len(all_labels)}\")\n    print(f\"ROC-AUC           : {roc_auc:.4f}\")\n    print(f\"PR-AUC            : {pr_auc:.4f}\")\n    print(f\"Accuracy          : {accuracy:.4f}\")\n    print(f\"F1-Score          : {f1:.4f}\")\n    \n    # Detailed evaluation by magnification\n    print(f\"\\n{'='*40}\")\n    print(\"MAGNIFICATION-SPECIFIC ANALYSIS\")\n    print(f\"{'='*40}\")\n    \n    results_by_mag = evaluate_by_magnification(model, breakhis_dataset, device)\n    \n    # Print summary table\n    print(f\"\\n{'='*80}\")\n    print(\"PERFORMANCE SUMMARY BY MAGNIFICATION\")\n    print(f\"{'='*80}\")\n    print(f\"{'Mag':<6} {'Samples':<8} {'Accuracy':<10} {'ROC-AUC':<10} {'PR-AUC':<10} {'F1-Score':<10}\")\n    print(f\"{'-'*80}\")\n    \n    for mag in sorted(results_by_mag.keys()):\n        r = results_by_mag[mag]\n        print(f\"{mag:<6} {r['sample_count']:<8} {r['accuracy']:<10.4f} \"\n              f\"{r['roc_auc']:<10.4f} {r['pr_auc']:<10.4f} {r['f1_score']:<10.4f}\")\n    \n    print(f\"{'-'*80}\")\n    print(f\"{'Overall':<6} {len(all_labels):<8} {accuracy:<10.4f} \"\n          f\"{roc_auc:<10.4f} {pr_auc:<10.4f} {f1:<10.4f}\")\n    \n    print(f\"\\n‚úÖ Analysis complete!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}