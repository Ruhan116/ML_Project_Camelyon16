{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12799368,"sourceType":"datasetVersion","datasetId":8086800}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-08-23T08:11:35.367293Z","iopub.execute_input":"2025-08-23T08:11:35.367551Z","iopub.status.idle":"2025-08-23T08:11:35.393531Z","shell.execute_reply.started":"2025-08-23T08:11:35.367531Z","shell.execute_reply":"2025-08-23T08:11:35.393024Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_y.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_y.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_meta.csv\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_x.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_mask.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_meta.csv\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_y.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_meta.csv\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_x.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_x.h5-001/camelyonpatch_level_2_split_train_x.h5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Core\nimport os\nimport time\nimport random\nimport yaml\nimport h5py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Torch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom torchvision.models.densenet import _DenseBlock\n\n# Metrics\nfrom sklearn.metrics import (\n    roc_auc_score,\n    average_precision_score,\n    accuracy_score,\n    f1_score,\n    classification_report,\n    confusion_matrix\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:14:26.867607Z","iopub.execute_input":"2025-08-23T08:14:26.868324Z","iopub.status.idle":"2025-08-23T08:14:26.872863Z","shell.execute_reply.started":"2025-08-23T08:14:26.868298Z","shell.execute_reply":"2025-08-23T08:14:26.872285Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import yaml\n\nconfig = {\n    \"seed\": 1337,\n    \"n_seeds\": 3,\n    \"device\": \"cuda:0\",\n    \"deterministic\": True,\n\n    \"data\": {\n        \"dataset_version\": \"pcam_v1\",\n        \"splits_file\": \"splits/patient_level_fold0.json\",\n        \"img_size\": 128,\n        \"normalize\": {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]},\n        \"decode\": \"pillow_rgb\",\n        \"stain_norm\": \"none\",\n        \"augment\": {\n            \"train\": [\n                {\"hflip\": 0.5},\n                {\"vflip\": 0.5},\n                {\"color_jitter\": {\"b\": 0.2, \"c\": 0.2, \"s\": 0.2}},\n                {\"blur\": {\"p\": 0.2, \"k\": 3}},\n            ],\n            \"val\": []\n        },\n        \"sampler\": \"random\",\n        \"samples_per_epoch\": None,\n    },\n\n    \"loader\": {\n        \"batch_size\": 64,\n        \"grad_accum\": 1,\n        \"num_workers\": 4,\n        \"pin_memory\": True,\n        \"persistent_workers\": True,\n    },\n\n    \"model\": {\n        \"backbone\": \"densenet121\",\n        \"weights\": \"imagenet_v1\",\n        \"precision\": \"fp32\",\n        \"dropout\": 0.0,\n        \"freeze_backbone\": False,\n        \"attention_type\": \"CBAM\",  # Options: \"SE\", \"ECA\", \"CBAM\", \"None\"\n        \"attention_params\": {\n            \"SE\": {\n                \"reduction\": 16\n            },\n            \"ECA\": {\n                \"k_size\": 3\n            },\n            \"CBAM\": {\n                \"reduction\": 16,\n                \"kernel_size\": 7\n            }\n        }\n    },\n\n    \"objective\": {\n        \"loss\": \"bce_logits\",\n        \"pos_weight\": None,\n        \"label_smoothing\": 0.0,\n        \"focal\": {\"enable\": False, \"alpha\": 0.25, \"gamma\": 2.0},\n        \"clip_grad_norm\": None,\n        \"calibration\": {\"enable\": False},\n        \"decision_threshold\": 0.5,\n        \"tta\": {\"enable\": False},\n    },\n\n    \"optim\": {\n        \"name\": \"adamw\",\n        \"lr\": 3.0e-4,\n        \"weight_decay\": 1.0e-4,\n        \"betas\": [0.9, 0.999],\n        \"schedule\": \"cosine\",\n        \"t_max\": 30,\n        \"warmup_steps\": 0,\n        \"epochs\": 10,\n        \"ema\": {\"enable\": False, \"decay\": 0.999},\n    },\n\n    \"eval\": {\n        \"metrics\": [\"roc_auc\", \"pr_auc\", \"acc\", \"f1\"],\n        \"ci_bootstrap\": 2000,\n        \"select_best_by\": \"roc_auc\",\n        \"eval_every\": \"epoch\",\n    },\n\n    \"env\": {\n        \"torch\": \"2.3.1\",\n        \"torchvision\": \"0.18.1\",\n        \"cuda\": \"12.1\",\n        \"cudnn_deterministic\": True,\n        \"cublas_workspace\": \":4096:8\",\n    }\n}\n\n# Save to YAML\nwith open(\"experiment.yaml\", \"w\") as f:\n    yaml.dump(config, f, sort_keys=False)\n\nprint(\"✅ experiment.yaml file created\")","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:14:30.513745Z","iopub.execute_input":"2025-08-23T08:14:30.514308Z","iopub.status.idle":"2025-08-23T08:14:30.526639Z","shell.execute_reply.started":"2025-08-23T08:14:30.514282Z","shell.execute_reply":"2025-08-23T08:14:30.525948Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ experiment.yaml file created\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import random, numpy as np, torch\n\nwith open(\"experiment.yaml\", \"r\") as f:\n    cfg = yaml.safe_load(f)\n\n# -----------------------------\n# Seed & Determinism\n# -----------------------------\ndef set_seed(seed: int, deterministic: bool = True):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    else:\n        torch.backends.cudnn.deterministic = False\n        torch.backends.cudnn.benchmark = True\n\nset_seed(cfg[\"seed\"], cfg[\"deterministic\"])\n\n# -----------------------------\n# Device\n# -----------------------------\ndevice = torch.device(cfg[\"device\"] if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:14:32.990407Z","iopub.execute_input":"2025-08-23T08:14:32.991108Z","iopub.status.idle":"2025-08-23T08:14:33.005049Z","shell.execute_reply.started":"2025-08-23T08:14:32.991081Z","shell.execute_reply":"2025-08-23T08:14:33.004461Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from torch.utils.data import Dataset\n# --------------------------------\n# Chunked Dataset for Memory Efficiency\n# --------------------------------\nclass PCamDatasetChunk(Dataset):\n    def __init__(self, h5_path, labels_path=None, transform=None, start_idx=0, end_idx=None):\n        \"\"\"\n        h5_path: path to HDF5 file with images\n        labels_path: path to HDF5 file with labels\n        transform: torchvision transforms\n        start_idx, end_idx: slice of the dataset to load (for splitting)\n        \"\"\"\n        self.h5_path = h5_path\n        self.labels_path = labels_path\n        self.transform = transform\n        \n        # Open HDF5 files and slice the dataset\n        self.h5_file = h5py.File(h5_path, \"r\")\n        key = \"x\" if \"x\" in self.h5_file else list(self.h5_file.keys())[0]\n        \n        if end_idx is None:\n            end_idx = len(self.h5_file[key])\n            \n        self.start_idx = start_idx\n        self.end_idx = end_idx\n        self.length = end_idx - start_idx\n        \n        # Memory-map the selected chunk\n        self.images = self.h5_file[key][start_idx:end_idx]\n        \n        # Load labels\n        self.labels = None\n        if labels_path is not None:\n            with h5py.File(labels_path, \"r\") as f:\n                self.labels = f[\"y\"][start_idx:end_idx]\n        \n        print(f\"Dataset chunk initialized: samples {start_idx} to {end_idx} ({self.length} total)\")\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        img = Image.fromarray(img)\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        if self.labels is not None:\n            label = int(self.labels[idx].item())\n            return img, label\n        else:\n            return img\n\n    def close(self):\n        if hasattr(self, 'h5_file') and self.h5_file:\n            self.h5_file.close()\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:14:34.636252Z","iopub.execute_input":"2025-08-23T08:14:34.636504Z","iopub.status.idle":"2025-08-23T08:14:34.643890Z","shell.execute_reply.started":"2025-08-23T08:14:34.636487Z","shell.execute_reply":"2025-08-23T08:14:34.643154Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# --------------------------------\n# Transforms from Config\n# --------------------------------\ncfg_data = cfg[\"data\"]\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((cfg_data[\"img_size\"], cfg_data[\"img_size\"])),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=cfg_data[\"normalize\"][\"mean\"], \n                        std=cfg_data[\"normalize\"][\"std\"])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((cfg_data[\"img_size\"], cfg_data[\"img_size\"])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=cfg_data[\"normalize\"][\"mean\"], \n                        std=cfg_data[\"normalize\"][\"std\"])\n])\n\n# --------------------------------\n# Dataset Paths\n# --------------------------------\nh5_train_x = \"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_x.h5-001/camelyonpatch_level_2_split_train_x.h5\"\nh5_train_y = \"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_y.h5\"\nh5_val_x   = \"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_x.h5\"\nh5_val_y   = \"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_y.h5\"\n\n# Get total training samples\nwith h5py.File(h5_train_x, \"r\") as f:\n    total_train = len(f[\"x\"])\n    print(f\"Total training samples: {total_train}\")\n\n# Split training data into chunks to manage memory\nnum_chunks = 4  # Split into 4 chunks (~65K samples each)\nchunk_size = total_train // num_chunks\ntrain_splits = []\n\nfor i in range(num_chunks):\n    start_idx = i * chunk_size\n    end_idx = (i + 1) * chunk_size if i < num_chunks - 1 else total_train\n    train_splits.append((start_idx, end_idx))\n\nprint(f\"Training data split into {num_chunks} chunks:\")\nfor i, (start, end) in enumerate(train_splits):\n    print(f\"  Chunk {i+1}: samples {start} to {end} ({end-start} samples)\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:14:38.115513Z","iopub.execute_input":"2025-08-23T08:14:38.116180Z","iopub.status.idle":"2025-08-23T08:14:38.137652Z","shell.execute_reply.started":"2025-08-23T08:14:38.116151Z","shell.execute_reply":"2025-08-23T08:14:38.137059Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total training samples: 262144\nTraining data split into 4 chunks:\n  Chunk 1: samples 0 to 65536 (65536 samples)\n  Chunk 2: samples 65536 to 131072 (65536 samples)\n  Chunk 3: samples 131072 to 196608 (65536 samples)\n  Chunk 4: samples 196608 to 262144 (65536 samples)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# --------------------------------\n# Create Validation Dataset\n# --------------------------------\nprint(\"\\nCreating validation dataset...\")\nval_dataset = PCamDatasetChunk(h5_val_x, labels_path=h5_val_y, transform=val_transform)\n\ncfg_loader = cfg[\"loader\"]\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=cfg_loader[\"batch_size\"], \n    shuffle=False, \n    num_workers=cfg_loader[\"num_workers\"], \n    pin_memory=cfg_loader[\"pin_memory\"]\n)\n\nprint(f\"Validation dataset created: {len(val_dataset)} samples, {len(val_loader)} batches\")","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:14:40.839087Z","iopub.execute_input":"2025-08-23T08:14:40.839722Z","iopub.status.idle":"2025-08-23T08:14:41.884667Z","shell.execute_reply.started":"2025-08-23T08:14:40.839702Z","shell.execute_reply":"2025-08-23T08:14:41.883803Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nCreating validation dataset...\nDataset chunk initialized: samples 0 to 32768 (32768 total)\nValidation dataset created: 32768 samples, 512 batches\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Squeeze-and-Excitation Module\nclass SqueezeExcitation(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(SqueezeExcitation, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).squeeze(-1).squeeze(-1)\n        y = self.fc1(y)\n        y = self.relu(y)\n        y = self.fc2(y)\n        y = self.sigmoid(y).unsqueeze(-1).unsqueeze(-1)\n        return x * y.expand_as(x)\n\n\n\n# CBAM Module\nclass ChannelAttention(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x).squeeze(3).squeeze(2))\n        max_out = self.fc(self.max_pool(x).squeeze(3).squeeze(2))\n        out = avg_out + max_out\n        return self.sigmoid(out).unsqueeze(2).unsqueeze(3)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        out = torch.cat([avg_out, max_out], dim=1)\n        out = self.conv(out)\n        return self.sigmoid(out)\n\nclass CBAM(nn.Module):\n    def __init__(self, channels, reduction=16, kernel_size=7):\n        super(CBAM, self).__init__()\n        self.ca = ChannelAttention(channels, reduction)\n        self.sa = SpatialAttention(kernel_size)\n\n    def forward(self, x):\n        out = x * self.ca(x)\n        out = out * self.sa(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:14:44.159600Z","iopub.execute_input":"2025-08-23T08:14:44.161530Z","iopub.status.idle":"2025-08-23T08:14:44.175284Z","shell.execute_reply.started":"2025-08-23T08:14:44.161485Z","shell.execute_reply":"2025-08-23T08:14:44.173838Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Efficient Channel Attention Module\nclass ECA(nn.Module):\n    def __init__(self, channels, k_size=3):\n        super(ECA, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        y = self.avg_pool(x)\n        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n        y = self.sigmoid(y)\n        return x * y.expand_as(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:14:45.973938Z","iopub.execute_input":"2025-08-23T08:14:45.974804Z","iopub.status.idle":"2025-08-23T08:14:45.979707Z","shell.execute_reply.started":"2025-08-23T08:14:45.974774Z","shell.execute_reply":"2025-08-23T08:14:45.979040Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# CBAM Module\nclass ChannelAttention(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x).squeeze(3).squeeze(2))\n        max_out = self.fc(self.max_pool(x).squeeze(3).squeeze(2))\n        out = avg_out + max_out\n        return self.sigmoid(out).unsqueeze(2).unsqueeze(3)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        out = torch.cat([avg_out, max_out], dim=1)\n        out = self.conv(out)\n        return self.sigmoid(out)\n\nclass CBAM(nn.Module):\n    def __init__(self, channels, reduction=16, kernel_size=7):\n        super(CBAM, self).__init__()\n        self.ca = ChannelAttention(channels, reduction)\n        self.sa = SpatialAttention(kernel_size)\n\n    def forward(self, x):\n        out = x * self.ca(x)\n        out = out * self.sa(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:14:46.784618Z","iopub.execute_input":"2025-08-23T08:14:46.785185Z","iopub.status.idle":"2025-08-23T08:14:46.792820Z","shell.execute_reply.started":"2025-08-23T08:14:46.785161Z","shell.execute_reply":"2025-08-23T08:14:46.792058Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# --------------------------------\n# Model Setup\n# --------------------------------\n\ncfg_model = cfg[\"model\"]\nprint(\"Creating model...\")\n\nif cfg_model[\"backbone\"] == \"densenet121\":\n    if cfg_model[\"weights\"] == \"imagenet_v1\":\n        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n    else:\n        model = models.densenet121(weights=None)\n    \n    # Modify features to add attention after each dense block\n    features_children = list(model.features.children())\n    new_modules = []\n    se_channels = [256, 512, 1024, 1024]  # Output channels after dense blocks\n    attn_count = 0\n    \n    for module in features_children:\n        new_modules.append(module)\n        if isinstance(module, _DenseBlock):  # Use imported _DenseBlock\n            attn_type = cfg_model[\"attention_type\"]\n            if attn_type == \"SE\":\n                attn = SqueezeExcitation(se_channels[attn_count], **cfg_model[\"attention_params\"][\"SE\"])\n            elif attn_type == \"ECA\":\n                attn = ECA(se_channels[attn_count], **cfg_model[\"attention_params\"][\"ECA\"])\n            elif attn_type == \"CBAM\":\n                attn = CBAM(se_channels[attn_count], **cfg_model[\"attention_params\"][\"CBAM\"])\n            else:\n                attn = None\n            if attn is not None:\n                new_modules.append(attn)\n                print(f\"Added {attn_type} after dense block {attn_count + 1}\")\n            attn_count += 1\n    \n    model.features = nn.Sequential(*new_modules)\n    print(f\"Pretrained weights preserved for original DenseNet121 layers\")\n    \n    # Modify classifier for binary classification\n    model.classifier = nn.Sequential(\n        nn.Dropout(cfg_model[\"dropout\"]),\n        nn.Linear(model.classifier.in_features, 1)\n    )\nelse:\n    raise NotImplementedError(f\"Backbone {cfg_model['backbone']} not implemented\")\n\nmodel = model.to(device)\n\nif cfg_model[\"freeze_backbone\"]:\n    for param in model.features.parameters():\n        param.requires_grad = False\n    print(\"Backbone frozen\")\n\n# Count and display parameters\ntry:\n    from tabulate import tabulate\n    table_available = True\nexcept ImportError:\n    table_available = False\n    print(\"Note: tabulate library not available, using plain print for parameter table\")\n\nprint(\"\\nModel Parameter Breakdown:\")\nparam_table = []\ntotal_params = 0\ntrainable_params = 0\n\nfor name, param in model.named_parameters():\n    param_count = param.numel()\n    total_params += param_count\n    if param.requires_grad:\n        trainable_params += param_count\n    param_table.append([name, str(tuple(param.shape)), f\"{param_count:,}\"])\n\nif table_available:\n    headers = [\"Layer Name\", \"Parameter Shape\", \"Number of Parameters\"]\n    print(tabulate(param_table, headers=headers, tablefmt=\"grid\"))\nelse:\n    print(\"Layer Name | Parameter Shape | Number of Parameters\")\n    print(\"-\" * 60)\n    for row in param_table:\n        print(f\"{row[0]:<40} | {row[1]:<15} | {row[2]:>10}\")\n\nprint(f\"\\n✅ Model created - Total params: {total_params:,}, Trainable: {trainable_params:,}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:15:28.360834Z","iopub.execute_input":"2025-08-23T08:15:28.361148Z","iopub.status.idle":"2025-08-23T08:15:28.790525Z","shell.execute_reply.started":"2025-08-23T08:15:28.361126Z","shell.execute_reply":"2025-08-23T08:15:28.789645Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Creating model...\nAdded CBAM after dense block 1\nAdded CBAM after dense block 2\nAdded CBAM after dense block 3\nAdded CBAM after dense block 4\nPretrained weights preserved for original DenseNet121 layers\n\nModel Parameter Breakdown:\n+---------------------------------------+-------------------+------------------------+\n| Layer Name                            | Parameter Shape   | Number of Parameters   |\n+=======================================+===================+========================+\n| features.0.weight                     | (64, 3, 7, 7)     | 9,408                  |\n+---------------------------------------+-------------------+------------------------+\n| features.1.weight                     | (64,)             | 64                     |\n+---------------------------------------+-------------------+------------------------+\n| features.1.bias                       | (64,)             | 64                     |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer1.norm1.weight   | (64,)             | 64                     |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer1.norm1.bias     | (64,)             | 64                     |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer1.conv1.weight   | (128, 64, 1, 1)   | 8,192                  |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer1.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer1.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer1.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer2.norm1.weight   | (96,)             | 96                     |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer2.norm1.bias     | (96,)             | 96                     |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer2.conv1.weight   | (128, 96, 1, 1)   | 12,288                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer2.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer2.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer2.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer3.norm1.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer3.norm1.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer3.conv1.weight   | (128, 128, 1, 1)  | 16,384                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer3.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer3.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer3.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer4.norm1.weight   | (160,)            | 160                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer4.norm1.bias     | (160,)            | 160                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer4.conv1.weight   | (128, 160, 1, 1)  | 20,480                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer4.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer4.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer4.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer5.norm1.weight   | (192,)            | 192                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer5.norm1.bias     | (192,)            | 192                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer5.conv1.weight   | (128, 192, 1, 1)  | 24,576                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer5.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer5.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer5.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer6.norm1.weight   | (224,)            | 224                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer6.norm1.bias     | (224,)            | 224                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer6.conv1.weight   | (128, 224, 1, 1)  | 28,672                 |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer6.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer6.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.4.denselayer6.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.5.ca.fc.0.weight             | (16, 256)         | 4,096                  |\n+---------------------------------------+-------------------+------------------------+\n| features.5.ca.fc.2.weight             | (256, 16)         | 4,096                  |\n+---------------------------------------+-------------------+------------------------+\n| features.5.sa.conv.weight             | (1, 2, 7, 7)      | 98                     |\n+---------------------------------------+-------------------+------------------------+\n| features.6.norm.weight                | (256,)            | 256                    |\n+---------------------------------------+-------------------+------------------------+\n| features.6.norm.bias                  | (256,)            | 256                    |\n+---------------------------------------+-------------------+------------------------+\n| features.6.conv.weight                | (128, 256, 1, 1)  | 32,768                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer1.norm1.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer1.norm1.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer1.conv1.weight   | (128, 128, 1, 1)  | 16,384                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer1.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer1.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer1.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer2.norm1.weight   | (160,)            | 160                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer2.norm1.bias     | (160,)            | 160                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer2.conv1.weight   | (128, 160, 1, 1)  | 20,480                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer2.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer2.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer2.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer3.norm1.weight   | (192,)            | 192                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer3.norm1.bias     | (192,)            | 192                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer3.conv1.weight   | (128, 192, 1, 1)  | 24,576                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer3.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer3.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer3.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer4.norm1.weight   | (224,)            | 224                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer4.norm1.bias     | (224,)            | 224                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer4.conv1.weight   | (128, 224, 1, 1)  | 28,672                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer4.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer4.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer4.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer5.norm1.weight   | (256,)            | 256                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer5.norm1.bias     | (256,)            | 256                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer5.conv1.weight   | (128, 256, 1, 1)  | 32,768                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer5.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer5.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer5.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer6.norm1.weight   | (288,)            | 288                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer6.norm1.bias     | (288,)            | 288                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer6.conv1.weight   | (128, 288, 1, 1)  | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer6.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer6.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer6.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer7.norm1.weight   | (320,)            | 320                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer7.norm1.bias     | (320,)            | 320                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer7.conv1.weight   | (128, 320, 1, 1)  | 40,960                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer7.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer7.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer7.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer8.norm1.weight   | (352,)            | 352                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer8.norm1.bias     | (352,)            | 352                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer8.conv1.weight   | (128, 352, 1, 1)  | 45,056                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer8.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer8.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer8.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer9.norm1.weight   | (384,)            | 384                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer9.norm1.bias     | (384,)            | 384                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer9.conv1.weight   | (128, 384, 1, 1)  | 49,152                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer9.norm2.weight   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer9.norm2.bias     | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer9.conv2.weight   | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer10.norm1.weight  | (416,)            | 416                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer10.norm1.bias    | (416,)            | 416                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer10.conv1.weight  | (128, 416, 1, 1)  | 53,248                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer10.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer10.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer10.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer11.norm1.weight  | (448,)            | 448                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer11.norm1.bias    | (448,)            | 448                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer11.conv1.weight  | (128, 448, 1, 1)  | 57,344                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer11.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer11.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer11.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer12.norm1.weight  | (480,)            | 480                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer12.norm1.bias    | (480,)            | 480                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer12.conv1.weight  | (128, 480, 1, 1)  | 61,440                 |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer12.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer12.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.7.denselayer12.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.8.ca.fc.0.weight             | (32, 512)         | 16,384                 |\n+---------------------------------------+-------------------+------------------------+\n| features.8.ca.fc.2.weight             | (512, 32)         | 16,384                 |\n+---------------------------------------+-------------------+------------------------+\n| features.8.sa.conv.weight             | (1, 2, 7, 7)      | 98                     |\n+---------------------------------------+-------------------+------------------------+\n| features.9.norm.weight                | (512,)            | 512                    |\n+---------------------------------------+-------------------+------------------------+\n| features.9.norm.bias                  | (512,)            | 512                    |\n+---------------------------------------+-------------------+------------------------+\n| features.9.conv.weight                | (256, 512, 1, 1)  | 131,072                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer1.norm1.weight  | (256,)            | 256                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer1.norm1.bias    | (256,)            | 256                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer1.conv1.weight  | (128, 256, 1, 1)  | 32,768                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer1.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer1.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer1.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer2.norm1.weight  | (288,)            | 288                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer2.norm1.bias    | (288,)            | 288                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer2.conv1.weight  | (128, 288, 1, 1)  | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer2.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer2.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer2.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer3.norm1.weight  | (320,)            | 320                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer3.norm1.bias    | (320,)            | 320                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer3.conv1.weight  | (128, 320, 1, 1)  | 40,960                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer3.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer3.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer3.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer4.norm1.weight  | (352,)            | 352                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer4.norm1.bias    | (352,)            | 352                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer4.conv1.weight  | (128, 352, 1, 1)  | 45,056                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer4.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer4.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer4.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer5.norm1.weight  | (384,)            | 384                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer5.norm1.bias    | (384,)            | 384                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer5.conv1.weight  | (128, 384, 1, 1)  | 49,152                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer5.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer5.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer5.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer6.norm1.weight  | (416,)            | 416                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer6.norm1.bias    | (416,)            | 416                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer6.conv1.weight  | (128, 416, 1, 1)  | 53,248                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer6.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer6.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer6.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer7.norm1.weight  | (448,)            | 448                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer7.norm1.bias    | (448,)            | 448                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer7.conv1.weight  | (128, 448, 1, 1)  | 57,344                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer7.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer7.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer7.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer8.norm1.weight  | (480,)            | 480                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer8.norm1.bias    | (480,)            | 480                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer8.conv1.weight  | (128, 480, 1, 1)  | 61,440                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer8.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer8.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer8.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer9.norm1.weight  | (512,)            | 512                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer9.norm1.bias    | (512,)            | 512                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer9.conv1.weight  | (128, 512, 1, 1)  | 65,536                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer9.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer9.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer9.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer10.norm1.weight | (544,)            | 544                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer10.norm1.bias   | (544,)            | 544                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer10.conv1.weight | (128, 544, 1, 1)  | 69,632                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer10.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer10.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer10.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer11.norm1.weight | (576,)            | 576                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer11.norm1.bias   | (576,)            | 576                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer11.conv1.weight | (128, 576, 1, 1)  | 73,728                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer11.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer11.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer11.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer12.norm1.weight | (608,)            | 608                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer12.norm1.bias   | (608,)            | 608                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer12.conv1.weight | (128, 608, 1, 1)  | 77,824                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer12.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer12.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer12.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer13.norm1.weight | (640,)            | 640                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer13.norm1.bias   | (640,)            | 640                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer13.conv1.weight | (128, 640, 1, 1)  | 81,920                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer13.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer13.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer13.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer14.norm1.weight | (672,)            | 672                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer14.norm1.bias   | (672,)            | 672                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer14.conv1.weight | (128, 672, 1, 1)  | 86,016                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer14.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer14.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer14.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer15.norm1.weight | (704,)            | 704                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer15.norm1.bias   | (704,)            | 704                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer15.conv1.weight | (128, 704, 1, 1)  | 90,112                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer15.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer15.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer15.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer16.norm1.weight | (736,)            | 736                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer16.norm1.bias   | (736,)            | 736                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer16.conv1.weight | (128, 736, 1, 1)  | 94,208                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer16.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer16.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer16.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer17.norm1.weight | (768,)            | 768                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer17.norm1.bias   | (768,)            | 768                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer17.conv1.weight | (128, 768, 1, 1)  | 98,304                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer17.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer17.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer17.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer18.norm1.weight | (800,)            | 800                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer18.norm1.bias   | (800,)            | 800                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer18.conv1.weight | (128, 800, 1, 1)  | 102,400                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer18.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer18.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer18.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer19.norm1.weight | (832,)            | 832                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer19.norm1.bias   | (832,)            | 832                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer19.conv1.weight | (128, 832, 1, 1)  | 106,496                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer19.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer19.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer19.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer20.norm1.weight | (864,)            | 864                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer20.norm1.bias   | (864,)            | 864                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer20.conv1.weight | (128, 864, 1, 1)  | 110,592                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer20.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer20.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer20.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer21.norm1.weight | (896,)            | 896                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer21.norm1.bias   | (896,)            | 896                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer21.conv1.weight | (128, 896, 1, 1)  | 114,688                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer21.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer21.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer21.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer22.norm1.weight | (928,)            | 928                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer22.norm1.bias   | (928,)            | 928                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer22.conv1.weight | (128, 928, 1, 1)  | 118,784                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer22.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer22.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer22.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer23.norm1.weight | (960,)            | 960                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer23.norm1.bias   | (960,)            | 960                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer23.conv1.weight | (128, 960, 1, 1)  | 122,880                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer23.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer23.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer23.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer24.norm1.weight | (992,)            | 992                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer24.norm1.bias   | (992,)            | 992                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer24.conv1.weight | (128, 992, 1, 1)  | 126,976                |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer24.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer24.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.10.denselayer24.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.11.ca.fc.0.weight            | (64, 1024)        | 65,536                 |\n+---------------------------------------+-------------------+------------------------+\n| features.11.ca.fc.2.weight            | (1024, 64)        | 65,536                 |\n+---------------------------------------+-------------------+------------------------+\n| features.11.sa.conv.weight            | (1, 2, 7, 7)      | 98                     |\n+---------------------------------------+-------------------+------------------------+\n| features.12.norm.weight               | (1024,)           | 1,024                  |\n+---------------------------------------+-------------------+------------------------+\n| features.12.norm.bias                 | (1024,)           | 1,024                  |\n+---------------------------------------+-------------------+------------------------+\n| features.12.conv.weight               | (512, 1024, 1, 1) | 524,288                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer1.norm1.weight  | (512,)            | 512                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer1.norm1.bias    | (512,)            | 512                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer1.conv1.weight  | (128, 512, 1, 1)  | 65,536                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer1.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer1.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer1.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer2.norm1.weight  | (544,)            | 544                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer2.norm1.bias    | (544,)            | 544                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer2.conv1.weight  | (128, 544, 1, 1)  | 69,632                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer2.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer2.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer2.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer3.norm1.weight  | (576,)            | 576                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer3.norm1.bias    | (576,)            | 576                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer3.conv1.weight  | (128, 576, 1, 1)  | 73,728                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer3.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer3.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer3.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer4.norm1.weight  | (608,)            | 608                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer4.norm1.bias    | (608,)            | 608                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer4.conv1.weight  | (128, 608, 1, 1)  | 77,824                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer4.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer4.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer4.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer5.norm1.weight  | (640,)            | 640                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer5.norm1.bias    | (640,)            | 640                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer5.conv1.weight  | (128, 640, 1, 1)  | 81,920                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer5.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer5.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer5.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer6.norm1.weight  | (672,)            | 672                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer6.norm1.bias    | (672,)            | 672                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer6.conv1.weight  | (128, 672, 1, 1)  | 86,016                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer6.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer6.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer6.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer7.norm1.weight  | (704,)            | 704                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer7.norm1.bias    | (704,)            | 704                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer7.conv1.weight  | (128, 704, 1, 1)  | 90,112                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer7.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer7.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer7.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer8.norm1.weight  | (736,)            | 736                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer8.norm1.bias    | (736,)            | 736                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer8.conv1.weight  | (128, 736, 1, 1)  | 94,208                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer8.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer8.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer8.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer9.norm1.weight  | (768,)            | 768                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer9.norm1.bias    | (768,)            | 768                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer9.conv1.weight  | (128, 768, 1, 1)  | 98,304                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer9.norm2.weight  | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer9.norm2.bias    | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer9.conv2.weight  | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer10.norm1.weight | (800,)            | 800                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer10.norm1.bias   | (800,)            | 800                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer10.conv1.weight | (128, 800, 1, 1)  | 102,400                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer10.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer10.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer10.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer11.norm1.weight | (832,)            | 832                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer11.norm1.bias   | (832,)            | 832                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer11.conv1.weight | (128, 832, 1, 1)  | 106,496                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer11.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer11.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer11.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer12.norm1.weight | (864,)            | 864                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer12.norm1.bias   | (864,)            | 864                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer12.conv1.weight | (128, 864, 1, 1)  | 110,592                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer12.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer12.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer12.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer13.norm1.weight | (896,)            | 896                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer13.norm1.bias   | (896,)            | 896                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer13.conv1.weight | (128, 896, 1, 1)  | 114,688                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer13.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer13.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer13.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer14.norm1.weight | (928,)            | 928                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer14.norm1.bias   | (928,)            | 928                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer14.conv1.weight | (128, 928, 1, 1)  | 118,784                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer14.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer14.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer14.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer15.norm1.weight | (960,)            | 960                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer15.norm1.bias   | (960,)            | 960                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer15.conv1.weight | (128, 960, 1, 1)  | 122,880                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer15.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer15.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer15.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer16.norm1.weight | (992,)            | 992                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer16.norm1.bias   | (992,)            | 992                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer16.conv1.weight | (128, 992, 1, 1)  | 126,976                |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer16.norm2.weight | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer16.norm2.bias   | (128,)            | 128                    |\n+---------------------------------------+-------------------+------------------------+\n| features.13.denselayer16.conv2.weight | (32, 128, 3, 3)   | 36,864                 |\n+---------------------------------------+-------------------+------------------------+\n| features.14.ca.fc.0.weight            | (64, 1024)        | 65,536                 |\n+---------------------------------------+-------------------+------------------------+\n| features.14.ca.fc.2.weight            | (1024, 64)        | 65,536                 |\n+---------------------------------------+-------------------+------------------------+\n| features.14.sa.conv.weight            | (1, 2, 7, 7)      | 98                     |\n+---------------------------------------+-------------------+------------------------+\n| features.15.weight                    | (1024,)           | 1,024                  |\n+---------------------------------------+-------------------+------------------------+\n| features.15.bias                      | (1024,)           | 1,024                  |\n+---------------------------------------+-------------------+------------------------+\n| classifier.1.weight                   | (1, 1024)         | 1,024                  |\n+---------------------------------------+-------------------+------------------------+\n| classifier.1.bias                     | (1,)              | 1                      |\n+---------------------------------------+-------------------+------------------------+\n\n✅ Model created - Total params: 7,258,377, Trainable: 7,258,377\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# --------------------------------\n# Training Setup\n# --------------------------------\ncfg_objective = cfg[\"objective\"]\ncfg_optim = cfg[\"optim\"]\n\ncriterion = nn.BCEWithLogitsLoss()\ndecision_threshold = cfg_objective[\"decision_threshold\"]\n\noptimizer = optim.AdamW(\n    model.parameters(),\n    lr=cfg_optim[\"lr\"],\n    weight_decay=cfg_optim[\"weight_decay\"],\n    betas=tuple(cfg_optim[\"betas\"])\n)\n\nscheduler = optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, T_max=cfg_optim[\"t_max\"]\n) if cfg_optim[\"schedule\"].lower() == \"cosine\" else None\n\nprint(\"✅ Training setup complete\")","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:15:47.102494Z","iopub.execute_input":"2025-08-23T08:15:47.102775Z","iopub.status.idle":"2025-08-23T08:15:47.109856Z","shell.execute_reply.started":"2025-08-23T08:15:47.102754Z","shell.execute_reply":"2025-08-23T08:15:47.109301Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ Training setup complete\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import gc\n# --------------------------------\n# Training Loop\n# --------------------------------\nepochs = cfg_optim[\"epochs\"]\ntrain_losses = []\nval_losses = []\nroc_aucs = []\npr_aucs = []\naccs = []\nf1s = []\n\nprint(f\"\\n{'='*60}\")\nprint(\"STARTING CHUNKED TRAINING\")\nprint(f\"{'='*60}\")\nprint(f\"Epochs: {epochs}, Chunks per epoch: {num_chunks}\")\n\ntotal_start_time = time.time()\n\nfor epoch in range(epochs):\n    epoch_start_time = time.time()\n    print(f\"\\n{'='*50}\")\n    print(f\"EPOCH {epoch+1}/{epochs}\")\n    print(f\"{'='*50}\")\n    \n    # Training phase - iterate through chunks\n    model.train()\n    epoch_train_loss = 0.0\n    epoch_train_samples = 0\n    \n    for chunk_idx, (start_idx, end_idx) in enumerate(train_splits):\n        chunk_start_time = time.time()\n        print(f\"\\nTraining on chunk {chunk_idx+1}/{num_chunks}: samples {start_idx} to {end_idx}\")\n        \n        # Create dataset for this chunk\n        train_dataset = PCamDatasetChunk(\n            h5_train_x, \n            labels_path=h5_train_y,\n            transform=train_transform,\n            start_idx=start_idx,\n            end_idx=end_idx\n        )\n        \n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=cfg_loader[\"batch_size\"],\n            shuffle=True, \n            num_workers=cfg_loader[\"num_workers\"], \n            pin_memory=cfg_loader[\"pin_memory\"]\n        )\n        \n        # Train on this chunk\n        chunk_loss = 0.0\n        chunk_samples = 0\n        \n        for step, (images, labels) in enumerate(train_loader):\n            images = images.to(device, non_blocking=True)\n            labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            chunk_loss += loss.item() * images.size(0)\n            chunk_samples += images.size(0)\n            \n            if step % 100 == 0:\n                current_loss = chunk_loss / chunk_samples\n                print(f\"  Step {step:4d}/{len(train_loader)} - Loss: {current_loss:.4f}\")\n        \n        # Close the chunk dataset\n        train_dataset.close()\n        del train_dataset, train_loader\n        gc.collect()\n        \n        chunk_time = time.time() - chunk_start_time\n        chunk_avg_loss = chunk_loss / chunk_samples\n        samples_per_sec = chunk_samples / chunk_time\n        \n        print(f\"  Chunk {chunk_idx+1} completed in {chunk_time:.1f}s - \"\n              f\"Loss: {chunk_avg_loss:.4f} - Speed: {samples_per_sec:.0f} samples/sec\")\n        \n        epoch_train_loss += chunk_loss\n        epoch_train_samples += chunk_samples\n    \n    # Calculate epoch training loss\n    epoch_train_loss /= epoch_train_samples\n    \n    # Validation phase\n    print(f\"\\nValidation...\")\n    val_start_time = time.time()\n    model.eval()\n    val_loss = 0.0\n    val_samples = 0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(val_loader):\n            images = images.to(device, non_blocking=True)\n            labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item() * images.size(0)\n            val_samples += images.size(0)\n            \n            # Collect predictions for metrics\n            preds = torch.sigmoid(outputs).cpu().numpy()\n            all_preds.append(preds)\n            all_labels.append(labels.cpu().numpy())\n    \n    val_time = time.time() - val_start_time\n    val_loss /= val_samples\n    \n    # Compute metrics\n    all_preds = np.vstack(all_preds)\n    all_labels = np.vstack(all_labels)\n    \n    roc_auc = roc_auc_score(all_labels, all_preds)\n    pr_auc = average_precision_score(all_labels, all_preds)\n    acc = accuracy_score(all_labels, (all_preds > decision_threshold).astype(int))\n    f1 = f1_score(all_labels, (all_preds > decision_threshold).astype(int))\n    \n    # Store metrics\n    train_losses.append(epoch_train_loss)\n    val_losses.append(val_loss)\n    roc_aucs.append(roc_auc)\n    pr_aucs.append(pr_auc)\n    accs.append(acc)\n    f1s.append(f1)\n    \n    # Epoch summary\n    epoch_time = time.time() - epoch_start_time\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"EPOCH {epoch+1} COMPLETE ({epoch_time:.1f}s total)\")\n    print(f\"{'='*60}\")\n    print(f\"Training Loss  : {epoch_train_loss:.4f}\")\n    print(f\"Validation     : {val_time:.1f}s - Loss: {val_loss:.4f}\")\n    print(f\"Metrics        : ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}\")\n    \n    if scheduler:\n        old_lr = optimizer.param_groups[0]['lr']\n        scheduler.step()\n        new_lr = optimizer.param_groups[0]['lr']\n        print(f\"Learning Rate  : {old_lr:.6f} -> {new_lr:.6f}\")\n    \n    # Clean up validation arrays\n    del all_preds, all_labels\n    gc.collect()\n\n# Training complete\ntotal_time = time.time() - total_start_time\navg_epoch_time = total_time / epochs\n\nprint(f\"\\n{'='*60}\")\nprint(\"TRAINING COMPLETED!\")\nprint(f\"{'='*60}\")\nprint(f\"Total time: {total_time/60:.1f} minutes\")\nprint(f\"Average epoch time: {avg_epoch_time:.1f} seconds\")\nprint(f\"Best ROC-AUC: {max(roc_aucs):.4f} (Epoch {roc_aucs.index(max(roc_aucs))+1})\")\n\n# Save results\ntorch.save(model.state_dict(), \"densenet121_chunked.pth\")\nprint(\"✅ Model saved to densenet121_chunked.pth\")","metadata":{"execution":{"iopub.status.busy":"2025-08-23T08:15:49.301217Z","iopub.execute_input":"2025-08-23T08:15:49.301776Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n============================================================\nSTARTING CHUNKED TRAINING\n============================================================\nEpochs: 10, Chunks per epoch: 4\n\n==================================================\nEPOCH 1/10\n==================================================\n\nTraining on chunk 1/4: samples 0 to 65536\nDataset chunk initialized: samples 0 to 65536 (65536 total)\n  Step    0/1024 - Loss: 0.7765\n  Step  100/1024 - Loss: 0.3200\n  Step  200/1024 - Loss: 0.2811\n  Step  300/1024 - Loss: 0.2613\n  Step  400/1024 - Loss: 0.2484\n  Step  500/1024 - Loss: 0.2389\n  Step  600/1024 - Loss: 0.2301\n  Step  700/1024 - Loss: 0.2236\n  Step  800/1024 - Loss: 0.2180\n  Step  900/1024 - Loss: 0.2126\n  Step 1000/1024 - Loss: 0.2089\n  Chunk 1 completed in 160.7s - Loss: 0.2074 - Speed: 408 samples/sec\n\nTraining on chunk 2/4: samples 65536 to 131072\nDataset chunk initialized: samples 65536 to 131072 (65536 total)\n  Step    0/1024 - Loss: 0.1386\n  Step  100/1024 - Loss: 0.1734\n  Step  200/1024 - Loss: 0.1702\n  Step  300/1024 - Loss: 0.1683\n  Step  400/1024 - Loss: 0.1673\n  Step  500/1024 - Loss: 0.1664\n  Step  600/1024 - Loss: 0.1642\n  Step  700/1024 - Loss: 0.1601\n  Step  800/1024 - Loss: 0.1577\n  Step  900/1024 - Loss: 0.1560\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ntraining_logs = pd.DataFrame({\n    \"epoch\": list(range(1, epochs+1)),\n    \"train_loss\": train_losses,\n    \"val_loss\": val_losses,\n    \"roc_auc\": roc_aucs,\n    \"pr_auc\": pr_aucs,\n    \"accuracy\": accs,\n    \"f1\": f1s\n})\ntraining_logs.to_csv(\"training_logs_chunked.csv\", index=False)\nprint(\"✅ Training logs saved to training_logs_chunked.csv\")\n\n# Clean up validation dataset\nval_dataset.close()\nprint(\"✅ Training complete - all resources cleaned up!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Load Trained Model\n# -----------------------------\ncfg_model = cfg[\"model\"]\n\n# Recreate model architecture\nif cfg_model[\"backbone\"] == \"densenet121\":\n    model = models.densenet121(weights=None)  # No pretrained weights needed for inference\n    model.classifier = nn.Sequential(\n        nn.Dropout(cfg_model[\"dropout\"]),\n        nn.Linear(model.classifier.in_features, 1)\n    )\nelse:\n    raise NotImplementedError(f\"Backbone {cfg_model['backbone']} not implemented\")\n\n# Load trained weights\nmodel_path = \"densenet121_chunked.pth\"  # or \"densenet121_best.pth\"\ntry:\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    print(f\"✅ Model loaded from {model_path}\")\nexcept FileNotFoundError:\n    print(f\"❌ Model file {model_path} not found. Please train the model first.\")\n    exit()\n\nmodel = model.to(device)\nmodel.eval()\n\n# -----------------------------\n# Test Dataset\n# -----------------------------\nfrom torchvision import transforms\nfrom PIL import Image\n\ncfg_data = cfg[\"data\"]\n\ntest_transform = transforms.Compose([\n    transforms.Resize((cfg_data[\"img_size\"], cfg_data[\"img_size\"])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=cfg_data[\"normalize\"][\"mean\"], \n                        std=cfg_data[\"normalize\"][\"std\"])\n])\n\nclass PCamDatasetChunk(Dataset):\n    def __init__(self, h5_path, labels_path=None, transform=None, start_idx=0, end_idx=None):\n        self.h5_path = h5_path\n        self.labels_path = labels_path\n        self.transform = transform\n        \n        self.h5_file = h5py.File(h5_path, \"r\")\n        key = \"x\" if \"x\" in self.h5_file else list(self.h5_file.keys())[0]\n        \n        if end_idx is None:\n            end_idx = len(self.h5_file[key])\n            \n        self.start_idx = start_idx\n        self.end_idx = end_idx\n        self.length = end_idx - start_idx\n        \n        self.images = self.h5_file[key][start_idx:end_idx]\n        \n        self.labels = None\n        if labels_path is not None:\n            with h5py.File(labels_path, \"r\") as f:\n                self.labels = f[\"y\"][start_idx:end_idx]\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        img = Image.fromarray(img)\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        if self.labels is not None:\n            label = int(self.labels[idx].item())\n            return img, label\n        else:\n            return img\n\n    def close(self):\n        if hasattr(self, 'h5_file') and self.h5_file:\n            self.h5_file.close()\n\n# Test dataset paths\nh5_test_x = \"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_x.h5\"\nh5_test_y = \"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_y.h5\"\n\nprint(\"Creating test dataset...\")\ntest_dataset = PCamDatasetChunk(h5_test_x, labels_path=h5_test_y, transform=test_transform)\n\ncfg_loader = cfg[\"loader\"]\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=cfg_loader[\"batch_size\"], \n    shuffle=False,  # Don't shuffle test data\n    num_workers=cfg_loader[\"num_workers\"], \n    pin_memory=cfg_loader[\"pin_memory\"]\n)\n\nprint(f\"Test dataset: {len(test_dataset)} samples, {len(test_loader)} batches\")\n\n# -----------------------------\n# Test Evaluation\n# -----------------------------\nprint(f\"\\n{'='*50}\")\nprint(\"EVALUATING ON TEST SET\")\nprint(f\"{'='*50}\")\n\ndecision_threshold = cfg[\"objective\"][\"decision_threshold\"]\n\nstart_time = time.time()\nall_preds = []\nall_labels = []\nall_probabilities = []\ntest_loss = 0.0\ncriterion = nn.BCEWithLogitsLoss()\n\nwith torch.no_grad():\n    for batch_idx, (images, labels) in enumerate(test_loader):\n        images = images.to(device, non_blocking=True)\n        labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n        \n        # Forward pass\n        outputs = model(images)\n        \n        # Calculate loss\n        loss = criterion(outputs, labels)\n        test_loss += loss.item() * images.size(0)\n        \n        # Get predictions and probabilities\n        probabilities = torch.sigmoid(outputs).cpu().numpy()\n        predictions = (probabilities > decision_threshold).astype(int)\n        \n        all_probabilities.append(probabilities)\n        all_preds.append(predictions)\n        all_labels.append(labels.cpu().numpy())\n        \n        if batch_idx % 100 == 0:\n            print(f\"  Processed batch {batch_idx}/{len(test_loader)}\")\n\nevaluation_time = time.time() - start_time\ntest_loss /= len(test_dataset)\n\n# Combine all predictions\nall_probabilities = np.vstack(all_probabilities)\nall_preds = np.vstack(all_preds)\nall_labels = np.vstack(all_labels)\n\nprint(f\"✅ Evaluation completed in {evaluation_time:.1f} seconds\")\n\n# -----------------------------\n# Calculate Metrics\n# -----------------------------\nprint(f\"\\n{'='*50}\")\nprint(\"TEST RESULTS\")\nprint(f\"{'='*50}\")\n\n# Core metrics\nroc_auc = roc_auc_score(all_labels, all_probabilities)\npr_auc = average_precision_score(all_labels, all_probabilities)\naccuracy = accuracy_score(all_labels, all_preds)\nf1 = f1_score(all_labels, all_preds)\n\nprint(f\"Test Loss      : {test_loss:.4f}\")\nprint(f\"ROC-AUC        : {roc_auc:.4f}\")\nprint(f\"PR-AUC         : {pr_auc:.4f}\")\nprint(f\"Accuracy       : {accuracy:.4f}\")\nprint(f\"F1-Score       : {f1:.4f}\")\n\n# Detailed classification report\nprint(f\"\\n{'='*30}\")\nprint(\"CLASSIFICATION REPORT\")\nprint(f\"{'='*30}\")\nclass_names = ['Normal', 'Tumor']\nprint(classification_report(all_labels.flatten(), all_preds.flatten(), \n                          target_names=class_names, digits=4))\n\n# Confusion Matrix\ncm = confusion_matrix(all_labels.flatten(), all_preds.flatten())\nprint(f\"\\nConfusion Matrix:\")\nprint(f\"{'':>8} {'Predicted':>18}\")\nprint(f\"{'':>8} {'Normal':>8} {'Tumor':>8}\")\nprint(f\"{'Normal':>8} {cm[0,0]:>8} {cm[0,1]:>8}\")\nprint(f\"{'Tumor':>8} {cm[1,0]:>8} {cm[1,1]:>8}\")\n\n# Calculate additional metrics\ntn, fp, fn, tp = cm.ravel()\nsensitivity = tp / (tp + fn)  # Recall for positive class\nspecificity = tn / (tn + fp)  # Recall for negative class\nprecision = tp / (tp + fp) if (tp + fp) > 0 else 0\nnpv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative predictive value\n\nprint(f\"\\nDetailed Metrics:\")\nprint(f\"Sensitivity (Recall)    : {sensitivity:.4f}\")\nprint(f\"Specificity             : {specificity:.4f}\")\nprint(f\"Precision (PPV)         : {precision:.4f}\")\nprint(f\"Negative Pred. Value    : {npv:.4f}\")\n\n# -----------------------------\n# Save Results\n# -----------------------------\nprint(f\"\\n{'='*50}\")\nprint(\"SAVING RESULTS\")\nprint(f\"{'='*50}\")\n\n# Save detailed results\ntest_results = {\n    'test_loss': test_loss,\n    'roc_auc': roc_auc,\n    'pr_auc': pr_auc,\n    'accuracy': accuracy,\n    'f1_score': f1,\n    'sensitivity': sensitivity,\n    'specificity': specificity,\n    'precision': precision,\n    'negative_predictive_value': npv,\n    'true_negatives': int(tn),\n    'false_positives': int(fp),\n    'false_negatives': int(fn),\n    'true_positives': int(tp),\n    'decision_threshold': decision_threshold,\n    'evaluation_time_seconds': evaluation_time\n}\n\n# Save as JSON\nimport json\nwith open('test_results.json', 'w') as f:\n    json.dump(test_results, f, indent=2)\n\n# Save predictions\npredictions_df = pd.DataFrame({\n    'sample_id': range(len(all_labels)),\n    'true_label': all_labels.flatten(),\n    'probability': all_probabilities.flatten(),\n    'prediction': all_preds.flatten(),\n    'correct': (all_labels.flatten() == all_preds.flatten()).astype(int)\n})\npredictions_df.to_csv('test_predictions.csv', index=False)\n\nprint(\"✅ Results saved to:\")\nprint(\"  - test_results.json (summary metrics)\")\nprint(\"  - test_predictions.csv (individual predictions)\")\n\n# -----------------------------\n# Optional: Create Visualizations\n# -----------------------------\ntry:\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    \n    # Set up plotting style\n    plt.style.use('default')\n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    \n    # 1. ROC Curve\n    from sklearn.metrics import roc_curve\n    fpr, tpr, _ = roc_curve(all_labels, all_probabilities)\n    \n    axes[0,0].plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})', linewidth=2)\n    axes[0,0].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n    axes[0,0].set_xlabel('False Positive Rate')\n    axes[0,0].set_ylabel('True Positive Rate')\n    axes[0,0].set_title('ROC Curve')\n    axes[0,0].legend()\n    axes[0,0].grid(True, alpha=0.3)\n    \n    # 2. Precision-Recall Curve\n    from sklearn.metrics import precision_recall_curve\n    precision_curve, recall_curve, _ = precision_recall_curve(all_labels, all_probabilities)\n    \n    axes[0,1].plot(recall_curve, precision_curve, label=f'PR Curve (AUC = {pr_auc:.4f})', linewidth=2)\n    axes[0,1].set_xlabel('Recall')\n    axes[0,1].set_ylabel('Precision')\n    axes[0,1].set_title('Precision-Recall Curve')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Confusion Matrix Heatmap\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names, ax=axes[1,0])\n    axes[1,0].set_title('Confusion Matrix')\n    axes[1,0].set_ylabel('True Label')\n    axes[1,0].set_xlabel('Predicted Label')\n    \n    # 4. Prediction Distribution\n    axes[1,1].hist(all_probabilities[all_labels.flatten() == 0], bins=50, alpha=0.7, \n                  label='Normal', color='blue', density=True)\n    axes[1,1].hist(all_probabilities[all_labels.flatten() == 1], bins=50, alpha=0.7, \n                  label='Tumor', color='red', density=True)\n    axes[1,1].axvline(decision_threshold, color='black', linestyle='--', \n                     label=f'Threshold ({decision_threshold})')\n    axes[1,1].set_xlabel('Prediction Probability')\n    axes[1,1].set_ylabel('Density')\n    axes[1,1].set_title('Prediction Distribution')\n    axes[1,1].legend()\n    axes[1,1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('test_evaluation_plots.png', dpi=300, bbox_inches='tight')\n    print(\"  - test_evaluation_plots.png (visualization)\")\n    \nexcept ImportError:\n    print(\"Note: matplotlib/seaborn not available for plotting\")\n\n# -----------------------------\n# Cleanup\n# -----------------------------\ntest_dataset.close()\nprint(\"\\n✅ Test evaluation complete!\")\n\n# Print final summary\nprint(f\"\\n{'='*60}\")\nprint(\"FINAL TEST SUMMARY\")\nprint(f\"{'='*60}\")\nprint(f\"Dataset: {len(test_dataset)} samples\")\nprint(f\"ROC-AUC: {roc_auc:.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\nprint(f\"Evaluation time: {evaluation_time:.1f} seconds\")\nprint(f\"{'='*60}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}