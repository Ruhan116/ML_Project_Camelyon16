{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12799368,"sourceType":"datasetVersion","datasetId":8086800}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:30:01.033073Z","iopub.execute_input":"2025-08-20T17:30:01.033327Z","iopub.status.idle":"2025-08-20T17:30:01.906899Z","shell.execute_reply.started":"2025-08-20T17:30:01.033294Z","shell.execute_reply":"2025-08-20T17:30:01.906062Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_y.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_y.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_meta.csv\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_x.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_mask.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_meta.csv\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_y.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_meta.csv\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_x.h5\n/kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_x.h5-001/camelyonpatch_level_2_split_train_x.h5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ===== 0) Imports & Setup =====\nimport os\nimport math\nimport h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom tqdm import tqdm\nimport torch.cuda.amp as amp\n\n# Reproducibility\nSEED = 1131\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n\n# Paths from Kaggle environment (updated for standard PCam dataset)\nBASE_DIR = \"/kaggle/input/pcamv1/pcamv1/\"\nTRAIN_X_PATH = os.path.join(BASE_DIR, \"camelyonpatch_level_2_split_train_x.h5-001/camelyonpatch_level_2_split_train_x.h5\")\nTRAIN_Y_PATH = os.path.join(BASE_DIR, \"camelyonpatch_level_2_split_train_y.h5\")\nVALID_X_PATH = os.path.join(BASE_DIR, \"camelyonpatch_level_2_split_valid_x.h5\")\nVALID_Y_PATH = os.path.join(BASE_DIR, \"camelyonpatch_level_2_split_valid_y.h5\")\nTEST_X_PATH = os.path.join(BASE_DIR, \"camelyonpatch_level_2_split_test_x.h5\")\nTEST_Y_PATH = os.path.join(BASE_DIR, \"camelyonpatch_level_2_split_test_y.h5\")\n\n# Verify paths\nfor path in [TRAIN_X_PATH, TRAIN_Y_PATH, VALID_X_PATH, VALID_Y_PATH, TEST_X_PATH, TEST_Y_PATH]:\n    if not os.path.exists(path):\n        print(f\"File not found: {path}\")\n    else:\n        print(f\"File found: {path}\")\n\n# Training hyperparameters\nINPUT_SIZE = 128  # Paper uses 128x128\nBATCH_SIZE = 128  # Adjust if OOM (64 or 96 safer)\nWARMUP_EPOCHS = 3\nFINETUNE_EPOCHS = 3\nLR_WARMUP = 1e-3\nLR_FINETUNE = 1e-4\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\n# Mixed precision\ntry:\n    from torch.amp import autocast, GradScaler  # Updated import\n    MIXED_PRECISION = True\n    print(\"Mixed precision enabled\")\nexcept:\n    MIXED_PRECISION = False\n    print(\"Mixed precision not available\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:30:16.145677Z","iopub.execute_input":"2025-08-20T17:30:16.146134Z","iopub.status.idle":"2025-08-20T17:30:25.284406Z","shell.execute_reply.started":"2025-08-20T17:30:16.146104Z","shell.execute_reply":"2025-08-20T17:30:25.283745Z"}},"outputs":[{"name":"stdout","text":"File found: /kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_x.h5-001/camelyonpatch_level_2_split_train_x.h5\nFile found: /kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_train_y.h5\nFile found: /kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_x.h5\nFile found: /kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_valid_y.h5\nFile found: /kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_x.h5\nFile found: /kaggle/input/pcamv1/pcamv1/camelyonpatch_level_2_split_test_y.h5\nUsing device: cuda\nMixed precision enabled\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Training hyperparameters\nINPUT_SIZE = 128  # Paper uses 128x128\nBATCH_SIZE = 128  # Adjust if OOM (64 or 96 safer)\nWARMUP_EPOCHS = 3\nFINETUNE_EPOCHS = 12\nLR_WARMUP = 1e-3\nLR_FINETUNE = 1e-4\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\n# Mixed precision\ntry:\n    from torch.cuda.amp import autocast, GradScaler\n    MIXED_PRECISION = True\n    print(\"Mixed precision enabled\")\nexcept:\n    MIXED_PRECISION = False\n    print(\"Mixed precision not available\")\n\n# ===== 1) HDF5 Dataset =====\nclass PCamH5Dataset(Dataset):\n    def __init__(self, x_path, y_path, transform=None):\n        self.x_file = h5py.File(x_path, \"r\")\n        self.y_file = h5py.File(y_path, \"r\")\n        self.X = self.x_file[\"x\"]  # (N, 96, 96, 3) uint8\n        self.Y = self.y_file[\"y\"]  # (N, 1, 1, 1)\n        self.transform = transform\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        # Load image and label\n        img = self.X[idx].astype(np.float32) / 255.0  # Normalize to [0,1]\n        label = float(self.Y[idx].reshape(-1)[0])\n        \n        # Convert to torch tensor (H,W,C -> C,H,W)\n        img = torch.from_numpy(img).permute(2, 0, 1)  # (3, 96, 96)\n        label = torch.tensor(label, dtype=torch.float32)\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, label\n\n    def close(self):\n        self.x_file.close()\n        self.y_file.close()\n\n# Data augmentation (as per paper)\ntrain_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=15),\n    transforms.RandomResizedCrop(INPUT_SIZE, scale=(0.85, 1.0)),\n])\n\nvalid_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n])\n\n# Create datasets\ntrain_dataset = PCamH5Dataset(TRAIN_X_PATH, TRAIN_Y_PATH, transform=train_transform)\nvalid_dataset = PCamH5Dataset(VALID_X_PATH, VALID_Y_PATH, transform=valid_transform)\ntest_dataset = PCamH5Dataset(TEST_X_PATH, TEST_Y_PATH, transform=valid_transform)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n\n# Compute class weights\ndef count_class_distribution(y_path, chunk=65536):\n    f = h5py.File(y_path, \"r\")\n    Y = f[\"y\"]\n    n = Y.shape[0]\n    ones = 0\n    for start in range(0, n, chunk):\n        end = min(start + chunk, n)\n        ones += Y[start:end].reshape(-1).sum()\n    zeros = n - int(ones)\n    f.close()\n    return zeros, int(ones)\n\nneg, pos = count_class_distribution(TRAIN_Y_PATH)\nprint(f\"Train label counts → 0: {neg}, 1: {pos}\")\nclasses = np.array([0, 1])\nweights = compute_class_weight(class_weight='balanced', classes=classes, y=np.array([0] * neg + [1] * pos))\nclass_weight_dict = {0: weights[0], 1: weights[1]}\nprint(\"Class weights:\", class_weight_dict)\n\n# Convert class weights to tensor for loss\nclass_weights_tensor = torch.tensor([class_weight_dict[0], class_weight_dict[1]], dtype=torch.float32).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:31:04.597968Z","iopub.execute_input":"2025-08-20T17:31:04.598252Z","iopub.status.idle":"2025-08-20T17:31:04.675290Z","shell.execute_reply.started":"2025-08-20T17:31:04.598230Z","shell.execute_reply":"2025-08-20T17:31:04.674680Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nMixed precision enabled\nTrain label counts → 0: 131072, 1: 131072\nClass weights: {0: 1.0, 1: 1.0}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ===== 1) HDF5 Dataset =====\nclass PCamH5Dataset(Dataset):\n    def __init__(self, x_path, y_path, transform=None):\n        self.x_file = h5py.File(x_path, \"r\")\n        self.y_file = h5py.File(y_path, \"r\")\n        self.X = self.x_file[\"x\"]  # (N, 96, 96, 3) uint8\n        self.Y = self.y_file[\"y\"]  # (N, 1, 1, 1)\n        self.transform = transform\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        img = self.X[idx].astype(np.float32) / 255.0  # Normalize to [0,1]\n        label = float(self.Y[idx].reshape(-1)[0])\n        img = torch.from_numpy(img).permute(2, 0, 1)  # (3, 96, 96)\n        label = torch.tensor(label, dtype=torch.float32)\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n    def close(self):\n        self.x_file.close()\n        self.y_file.close()\n\n# Data augmentation (as per paper)\ntrain_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=15),\n    transforms.RandomResizedCrop(INPUT_SIZE, scale=(0.85, 1.0)),\n])\n\nvalid_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n])\n\n# Create datasets\ntrain_dataset = PCamH5Dataset(TRAIN_X_PATH, TRAIN_Y_PATH, transform=train_transform)\nvalid_dataset = PCamH5Dataset(VALID_X_PATH, VALID_Y_PATH, transform=valid_transform)\ntest_dataset = PCamH5Dataset(TEST_X_PATH, TEST_Y_PATH, transform=valid_transform)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n\n# Compute class weights\ndef count_class_distribution(y_path, chunk=65536):\n    f = h5py.File(y_path, \"r\")\n    Y = f[\"y\"]\n    n = Y.shape[0]\n    ones = 0\n    for start in range(0, n, chunk):\n        end = min(start + chunk, n)\n        ones += Y[start:end].reshape(-1).sum()\n    zeros = n - int(ones)\n    f.close()\n    return zeros, int(ones)\n\nneg, pos = count_class_distribution(TRAIN_Y_PATH)\nprint(f\"Train label counts → 0: {neg}, 1: {pos}\")\nclasses = np.array([0, 1])\nweights = compute_class_weight(class_weight='balanced', classes=classes, y=np.array([0] * neg + [1] * pos))\nclass_weight_dict = {0: weights[0], 1: weights[1]}\nprint(\"Class weights:\", class_weight_dict)\n\nclass_weights_tensor = torch.tensor([class_weight_dict[0], class_weight_dict[1]], dtype=torch.float32).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:31:09.597588Z","iopub.execute_input":"2025-08-20T17:31:09.598214Z","iopub.status.idle":"2025-08-20T17:31:09.832645Z","shell.execute_reply.started":"2025-08-20T17:31:09.598191Z","shell.execute_reply":"2025-08-20T17:31:09.832008Z"}},"outputs":[{"name":"stdout","text":"Train label counts → 0: 131072, 1: 131072\nClass weights: {0: 1.0, 1: 1.0}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ===== 2) Model Definition =====\nclass DNBCD(nn.Module):\n    def __init__(self):\n        super(DNBCD, self).__init__()\n        self.backbone = models.densenet121(pretrained=True)\n        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])  # Remove classifier\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.dropout1 = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(1024, 256)\n        self.bn = nn.BatchNorm1d(256)\n        self.relu = nn.ReLU()\n        self.dropout2 = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(256, 1)  # Output raw logits\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout1(x)\n        x = self.fc1(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        return x\n\n# Initialize model\nmodel = DNBCD().to(DEVICE)\n\n# Freeze backbone for warmup\nfor param in model.backbone.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:31:13.489249Z","iopub.execute_input":"2025-08-20T17:31:13.489813Z","iopub.status.idle":"2025-08-20T17:31:13.944617Z","shell.execute_reply.started":"2025-08-20T17:31:13.489791Z","shell.execute_reply":"2025-08-20T17:31:13.943862Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 210MB/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ===== 3) Training Setup =====\ncriterion = nn.BCEWithLogitsLoss(reduction='none')  # For logits + per-sample weighting\noptimizer = optim.AdamW(model.parameters(), lr=LR_WARMUP)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\nscaler = GradScaler() if MIXED_PRECISION else None\nbest_auc = 0.0\nckpt_path = \"/kaggle/working/dnbcd_pcam_best.pth\"\n\n\ndef train_epoch(loader, model, criterion, optimizer, scaler, class_weights_tensor):\n    model.train()\n    total_loss, total_correct, total_samples = 0, 0, 0\n    all_probs, all_labels = [], []\n    \n    progress_bar = tqdm(loader, desc=\"Training\")\n    \n    for images, labels in progress_bar:\n        images, labels = images.to(DEVICE), labels.to(DEVICE).float()\n        \n        optimizer.zero_grad()\n        \n        if MIXED_PRECISION:\n            # Fixed autocast usage\n            with torch.cuda.amp.autocast():\n                outputs = model(images).squeeze()\n                loss = criterion(outputs, labels)\n                # Apply class weights\n                weights = class_weights_tensor[labels.long()]\n                loss = (loss * weights).mean()\n        else:\n            outputs = model(images).squeeze()\n            loss = criterion(outputs, labels)\n            weights = class_weights_tensor[labels.long()]\n            loss = (loss * weights).mean()\n        \n        if MIXED_PRECISION:\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            optimizer.step()\n        \n        total_loss += loss.item()\n        predicted = (torch.sigmoid(outputs) > 0.5).float()\n        total_correct += (predicted == labels).sum().item()\n        total_samples += labels.size(0)\n        \n        all_probs.extend(torch.sigmoid(outputs).cpu().detach().numpy())\n        all_labels.extend(labels.cpu().numpy())\n        \n        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    accuracy = total_correct / total_samples\n    auc = roc_auc_score(all_labels, all_probs)\n    avg_loss = total_loss / len(loader)\n    \n    return avg_loss, accuracy, auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:31:29.113222Z","iopub.execute_input":"2025-08-20T17:31:29.113985Z","iopub.status.idle":"2025-08-20T17:31:29.126803Z","shell.execute_reply.started":"2025-08-20T17:31:29.113957Z","shell.execute_reply":"2025-08-20T17:31:29.126122Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/tmp/ipykernel_36/253108213.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler() if MIXED_PRECISION else None\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:32:59.851021Z","iopub.execute_input":"2025-08-20T17:32:59.851331Z","iopub.status.idle":"2025-08-20T17:32:59.855475Z","shell.execute_reply.started":"2025-08-20T17:32:59.851307Z","shell.execute_reply":"2025-08-20T17:32:59.854770Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def validate_epoch(loader, model, criterion, class_weights_tensor):\n    model.eval()\n    total_loss, total_correct, total_samples = 0, 0, 0\n    all_probs, all_labels = [], []\n    \n    with torch.no_grad():\n        progress_bar = tqdm(loader, desc=\"Validation\")\n        \n        for images, labels in progress_bar:\n            images, labels = images.to(DEVICE), labels.to(DEVICE).float()\n            \n            if MIXED_PRECISION:\n                # Fixed autocast usage\n                with torch.cuda.amp.autocast():\n                    outputs = model(images).squeeze()\n                    loss = criterion(outputs, labels)\n                    weights = class_weights_tensor[labels.long()]\n                    loss = (loss * weights).mean()\n            else:\n                outputs = model(images).squeeze()\n                loss = criterion(outputs, labels)\n                weights = class_weights_tensor[labels.long()]\n                loss = (loss * weights).mean()\n            \n            total_loss += loss.item()\n            predicted = (torch.sigmoid(outputs) > 0.5).float()\n            total_correct += (predicted == labels).sum().item()\n            total_samples += labels.size(0)\n            \n            all_probs.extend(torch.sigmoid(outputs).cpu().detach().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    accuracy = total_correct / total_samples\n    auc = roc_auc_score(all_labels, all_probs)\n    avg_loss = total_loss / len(loader)\n    \n    return avg_loss, accuracy, auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:33:06.086582Z","iopub.execute_input":"2025-08-20T17:33:06.087175Z","iopub.status.idle":"2025-08-20T17:33:06.093871Z","shell.execute_reply.started":"2025-08-20T17:33:06.087153Z","shell.execute_reply":"2025-08-20T17:33:06.093113Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ===== 4) Training Loop =====\nprint(\"Starting warm-up training phase...\")\nhistory = {'train_loss': [], 'train_acc': [], 'train_auc': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}\n\nfor epoch in range(WARMUP_EPOCHS):\n    train_loss, train_acc, train_auc = train_epoch(train_loader, model, criterion, optimizer, scaler, class_weights_tensor)\n    val_loss, val_acc, val_auc = validate_epoch(valid_loader, model, criterion, class_weights_tensor)\n    \n    print(f\"Epoch {epoch+1}/{WARMUP_EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, AUC: {train_auc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}\")\n    \n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['train_auc'].append(train_auc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    history['val_auc'].append(val_auc)\n    \n    scheduler.step(val_auc)\n    \n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), ckpt_path)\n        print(f\"Saved best model with AUC {best_auc:.4f}\")\n\n# Fine-tuning phase\nprint(\"Starting fine-tuning phase...\")\nfor param in model.backbone.parameters():\n    param.requires_grad = True\n\noptimizer = optim.AdamW(model.parameters(), lr=LR_FINETUNE)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n\nfor epoch in range(FINETUNE_EPOCHS):\n    train_loss, train_acc, train_auc = train_epoch(train_loader, model, criterion, optimizer, scaler, class_weights_tensor)\n    val_loss, val_acc, val_auc = validate_epoch(valid_loader, model, criterion, class_weights_tensor)\n    \n    print(f\"Epoch {epoch+1}/{FINETUNE_EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, AUC: {train_auc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}\")\n    \n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['train_auc'].append(train_auc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    history['val_auc'].append(val_auc)\n    \n    scheduler.step(val_auc)\n    \n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), ckpt_path)\n        print(f\"Saved best model with AUC {best_auc:.4f}\")\n\nprint(f\"Training completed! Best validation AUC: {best_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:33:13.193525Z","iopub.execute_input":"2025-08-20T17:33:13.193812Z"}},"outputs":[{"name":"stdout","text":"Starting warm-up training phase...\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/2048 [00:00<?, ?it/s]/tmp/ipykernel_36/253108213.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nTraining: 100%|██████████| 2048/2048 [18:28<00:00,  1.85it/s, loss=0.3094]\nValidation:   0%|          | 0/256 [00:00<?, ?it/s]/tmp/ipykernel_36/3833274556.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nValidation: 100%|██████████| 256/256 [00:42<00:00,  6.06it/s, loss=0.4290]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\nTrain Loss: 0.3905, Acc: 0.8228, AUC: 0.9045\nVal Loss: 0.3993, Acc: 0.8128, AUC: 0.9072\nSaved best model with AUC 0.9072\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/2048 [00:00<?, ?it/s]/tmp/ipykernel_36/253108213.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nTraining: 100%|██████████| 2048/2048 [16:49<00:00,  2.03it/s, loss=0.3257]\nValidation:   0%|          | 0/256 [00:00<?, ?it/s]/tmp/ipykernel_36/3833274556.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nValidation: 100%|██████████| 256/256 [00:32<00:00,  7.96it/s, loss=0.4433]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3\nTrain Loss: 0.3607, Acc: 0.8399, AUC: 0.9193\nVal Loss: 0.3916, Acc: 0.8143, AUC: 0.9131\nSaved best model with AUC 0.9131\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/2048 [00:00<?, ?it/s]/tmp/ipykernel_36/253108213.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nTraining: 100%|██████████| 2048/2048 [16:46<00:00,  2.03it/s, loss=0.3202]\nValidation:   0%|          | 0/256 [00:00<?, ?it/s]/tmp/ipykernel_36/3833274556.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nValidation: 100%|██████████| 256/256 [00:32<00:00,  7.88it/s, loss=0.4690]\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3\nTrain Loss: 0.3510, Acc: 0.8451, AUC: 0.9237\nVal Loss: 0.4214, Acc: 0.8098, AUC: 0.9105\nStarting fine-tuning phase...\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/2048 [00:00<?, ?it/s]/tmp/ipykernel_36/253108213.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nTraining:  92%|█████████▏| 1894/2048 [19:55<01:35,  1.61it/s, loss=0.1211]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ===== 5) Evaluation =====\nmodel.load_state_dict(torch.load(ckpt_path))\nmodel.eval()\n\ntest_loss, test_acc, test_auc = validate_epoch(test_loader, model, criterion, class_weights_tensor)\nprint(f\"Test Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, AUC: {test_auc:.4f}\")\n\n# Detailed metrics\npreds, trues = [], []\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n        images = images.to(DEVICE)\n        with autocast('cuda', enabled=MIXED_PRECISION):  # Updated autocast\n            outputs = model(images).squeeze()\n        preds.extend(torch.sigmoid(outputs).cpu().numpy())  # Apply sigmoid for metrics\n        trues.extend(labels.cpu().numpy())\n\nprint(classification_report(trues, (np.array(preds) > 0.5).astype(int), target_names=['No Metastasis', 'Metastasis']))\n\n# Confusion matrix\ncm = confusion_matrix(trues, (np.array(preds) > 0.5).astype(int))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Metastasis', 'Metastasis'], yticklabels=['No Metastasis', 'Metastasis'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# Plot training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history['train_acc'], label='Train Acc')\nplt.plot(history['val_acc'], label='Val Acc')\nplt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history['train_loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Val Loss')\nplt.title('Loss')\nplt.legend()\nplt.show()\n\n# Clean up\ntrain_dataset.close()\nvalid_dataset.close()\ntest_dataset.close()\n\nprint(\"Training and evaluation completed!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}